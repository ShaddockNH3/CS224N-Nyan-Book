从基本序列模型到RNN

---
## 1. Language Modeling

第一部分：什么是语言模型

"The students opened their ------ ."  
(学生们打开了他们的 ------ )

语言模型 (Language Model, LM)，就是一个给一段文本**分配概率**的系统。它会告诉我们，“the students opened their books” 这句话听起来有多“自然”，而 “the students opened their bananas” 听起来又有多“奇怪”

---

第二部分：语言模型的超能力。—— 从“猜词”到“万能”

一个足够强大的语言模型能做的事情，远远不止“猜下一个词”那么简单。

- **常识问答 [Trivia]:** "斯坦福大学位于加州的 ______。" -> `Palo Alto`
    
- **语法判断 [Syntax]:** "我把叉子放在了桌子上。" (它知道 `put a fork` 而不是 `put ___ fork`)
    
- **指代消解 [Coreference]:** "那个女人过马路时，回头看了一下她**自己**的肩膀。" (它知道 `her shoulder` 指的是那个女人)
    
- **情感分析 [Sentiment]:** "这部电影的唯一价值就是爆米花和饮料。这部电影真是 ____。" -> `糟糕`
    
- **简单推理 [Reasoning]:** "艾洛进厨房泡茶。站在他旁边的祖寇在思索自己的命运。祖寇离开了 ____。" -> `厨房`

---

第三部分：n-gram 语言模型

在深度学习的“神经网络”出现之前，此前的计算机科学家用一种非常直观的方法来建造这个预测模型——**n-gram 模型**。这是一种基于**统计**和**计数**的模型。

- **什么是 n-gram？** 就是一段连续的、长度为 n 的词语。
    
    - **unigram (1-gram):** "the", "students"
        
    - **bigram (2-gram):** "the students", "students opened"
        
    - **trigram (3-gram):** "the students opened"
        
- **核心思想 (马尔科夫假设):** 这是一个“短视”的假设。它认为，要预测下一个词，我们**不需要看整篇文章**，只需要看它前面紧邻的 `n-1` 个词就足够了。
    
    - 比如一个 4-gram 模型，在预测 "students opened their ____" 的下一个词时，它只会关注前面的 "students opened their" 这3个词。
        
- **如何计算？** 超级简单，就是**数数**。
    
    - P(books | students opened their) = "students opened their **books**" 这个词组在整本书里出现的次数 / "students opened their" 这个词组在整本书里出现的次数。
        
    - 如果前者出现了400次，后者出现了1000次，那么概率就是 400/1000 = 0.4。

---

第四部分：n-gram模型的局限性

- **问题一：稀疏性 (Sparsity Problem) - “我没见过。”**
    
    - **问题1:** 如果我们的语料库里，从来没有出现过 "students opened their" 这个组合怎么办？那分母就是0，我们就完全没法计算了。
        
    - **问题2:** 即使出现过 "students opened their"，但如果后面从来没跟过 "laptops" 这个词，那 "laptops" 的概率就永远是0。这显然不合理。
        
    - **“尝试的解决方案”:**
        
        - **回退 (Backoff):** 如果 3-gram 找不到，那我就降低要求，只看 2-gram "opened their"，用它的统计数据来猜。
            
        - **平滑 (Smoothing):** 假装每个词组合都至少出现过一个超级小的次数（比如0.001次），强行避免概率为0的尴尬。
            
- **问题二：存储爆炸 (Storage Problem) - “我的脑子要炸了。”**
    
    - 模型需要把**所有**在语料库里见过的 n-gram 组合及其出现次数，全都背下来。如果语料库变大，或者 n 稍微增加一点（比如从3到5），这个需要记忆的“字典”就会变得比整个图书馆还要大，根本存不下。
        
- **问题三：短视 (Incoherence) - “只会说胡话”**
    
    - 讲义里用 n-gram 模型生成的文本非常形象。"today the price of gold per ton..."
        
    - **局部看：** 每三四个词连在一起，语法都还挺通顺的。
        
    - **整体看：** 整段话完全不知所云，前言不搭后语。这就是因为它只看眼前两三个词的“短视”造成的。它完全没有“大局观”。

---

第五部分：固定窗口神经网络模型

为了打破这些缺陷，新一代的“神经网络”登场。他们提出的第一个改良方案，就是我们非常熟悉的**固定窗口神经网络模型 (Fixed-window neural LM)**。

- **事实上，这就是此前pytorch速成课实现的模型
    
    1. **输入：** 同样取一个固定的窗口，比如 "the students opened their"。
        
    2. **Embedding 层：** 把每个单词都从“学号”转换成它在已有词汇库上的上的“单词向量” (Word Embedding)。
        
    3. **拼接：** 把这4个单词向量拼接在一起，形成一个长长的大向量。
        
    4. **隐藏层：** 将这个大向量输入一个带 `ReLU` 或 `Tanh` 的隐藏层进行“思考”。
        
    5. **输出层 (Softmax)：** 最终，输出层会为**词汇表里的每一个词**都给出一个概率。告诉我们下一个词是 "books" 的概率是多少，是 "laptops" 的概率是多少……

---

第六部分：优点和局限性

- **优点1：解决了稀疏性。**
    
    - 因为模型是在“单词向量”的层面进行思考的。即使它从未见过 "students opened their **laptops**"，但如果它知道 "laptops" 的味道和 "books" 的味道很像，它就能举一反三，给 "laptops" 一个不为零的、合理的概率。**它学会了泛化。**
        
- **优点2：解决了存储爆炸。**
    
    - 模型不再需要记住所有 n-gram 的次数了。它只需要存储神经网络的**权重参数** (`W` 和 `b`)。这个大小是固定的，和语料库的大小无关。
        

**但是，新的烦恼也随之而来：**

- **烦恼1：窗口仍然是固定的、太小。**
    
    - 它还是一个“短视”的模型，无法看到窗口之外的关键信息。
        
- **烦恼2：权重矩阵 `W` 太大。**
    
    - 如果我们想扩大窗口（比如从4个词增加到10个词），那第一层隐藏层的权重矩阵 `W` 就会变得异常巨大，难以训练。
        
- **烦恼3：缺乏“对称性” (最关键的缺陷。) **
    
    - 处理窗口里**第一个词**的权重，和处理**第二个词**的权重，是**完全独立的、不共享的**。模型无法理解“一个词，无论出现在哪个位置，它都还是那个词”。它必须为每个“位置”都单独学习一套处理规则，这非常低效。

---

第七部分：

讲义的最后，留下了一个激动人心的悬念，为我们指向了真正的未来：

> "We need a neural architecture that can process **any length input**"  
> (我们需要一个能处理**任意长度输入**的神经网络结构)

这意味着，我们需要一个全新的、更强大的大脑结构。它不再有“固定窗口”的限制，它拥有**记忆**，可以从一句话的开头一直读到结尾，并记住前面所有的关键信息。

这个结构，就是我们马上要学习的——**循环神经网络 (RNN)**。

---
### 2. Recurrent Neural Networks (RNN)

第一部分：记忆的诞生

还记得我们之前的固定窗口模型吗？它就像一个流水线工人，为每个位置的词都准备了一套不同的工具，笨重且短视。而RNN，则是一位拥有**一个超级工具箱**的宗师级工匠。

**核心思想：重复使用同一套权重 (Apply the same weights W repeatedly)**

- RNN的大脑里，只有**一套核心的思考逻辑**（一组权重 `W`）。
    
- 当它读到第一个词时，用这套逻辑思考一下；读到第二个词时，**还是用这同一套逻辑**来思考……
    
- 这就像我们人类，是用同一个大脑来理解一句话里的每一个词，而不是为“第一个词”准备一个大脑，为“第二个词”又换一个大脑。这种**“对称性”**是RNN的第一个巨大飞跃。

**秘密武器：隐藏状态 (Hidden State, `h_t`) —— 流动的“思想火花”**

- 这正是RNN“记忆”的秘密所在。`h_t` 可以被想象成RNN在读到第 `t` 个词时的**“瞬时记忆”**或**“思考总结”**。
    
- 它的工作流程就像一个美妙的“思想接力赛”：
    
    1. **t=1时：** RNN读到第一个词 `x_1`，它会把它变成一个“思想火花” `h_1`。
        
    2. **t=2时：** RNN读到第二个词 `x_2`。这时，它做的不是从零开始思考，而是把**“新的词 `x_2`”**和**“上一步的思考总结 `h_1`”**放在一起，共同提炼出一个**新的“思想火花” `h_2`**。
        
    3. **t=3时：** 它又会把**“新的词 `x_3`”**和**“上一步的思考总结 `h_2`”**放在一起，提炼出 `h_3`……
        
- 就这样，**“思想火花” `h_t` 像一条记忆的丝带，在整个句子中流动和传递**，把前面所有词的信息，都不断地浓缩和累积下来。

---

第二部分：RNN的优点与缺点

优点

- **优点1：能处理任意长度的输入。** 不再有“窗口大小”的限制，给它一首诗，它能读；给它一篇小说，它也能读。
    
- **优点2：理论上拥有长时记忆。** `t` 时刻的计算，理论上可以利用到很久很久之前的信息。
    
- **优点3：模型大小是固定的。** 不管输入多长，它的“大脑”权重 `W` 都是那一套，不会变大。
    
- **优点4：处理方式对称。** 对每个词都一视同仁，学习效率更高。


缺点

- **缺点1：计算速度慢。** 因为必须一个词一个词地按顺序读，不能像CNN那样“一目十行”，所以训练和推理都比较慢。
    
- **缺点2：记忆会“褪色”。(梯度消失/爆炸)** 对于特别特别长的句子，就像我们记不住小说第一章的某个细节一样，RNN的“思想火花”传到后面，也可能会把最开始的信息给忘了。

---

第三部分：如何训练RNN

教导RNN的过程，就像是在陪它一起逐字逐句地精读一本书。

- **任务目标：** 在每一步 `t`，根据已经读过的所有词（都被浓缩在 `h_{t-1}` 里了），预测下一个词 `x_t` 应该是什么。
    
- **损失函数 (Loss Function)：** 在每一步，我们都对它进行一次“随堂小测”。
    
    - 模型在读完 "the" 之后，会给出一个对下一个词的**概率预测**（比如 "students" 概率0.3, "cat" 概率0.01...）。
        
    - 我们拿出“标准答案”——书上写的确实是 "students"。
        
    - **交叉熵损失 (Cross-entropy loss)** 就是用来衡量模型的“惊讶程度”的。如果模型给正确答案的概率很低，那它的“惊讶值”（损失）就很大。
        
    - 我们把一整个句子，每一步的“惊讶值”全都加起来，就是这个句子的总损失。
        
- **一个技巧：“教师强制” (Teacher Forcing)**
    
    - 这是一个非常重要的细节。在训练时，假设模型在预测完 "students" 之后，它自己猜的下一个词是 "ate"。
        
    - 我们下一步应该拿什么给它当输入呢？是它自己猜错的 "ate"，还是书上正确的 "opened"？
        
    - **答案是：用书上正确的 "opened"。**
        
    - 这就是“教师强制”。我们像一位温柔的老师，在它每一步走错时，都及时把它拉回到正确的轨道上，而不是让它“错上加错”，越跑越偏。这能让训练过程稳定得多。
        
- **现实中的训练：随机梯度下降 (SGD)**
    
    - 让模型一次性读完一整个图书馆（整个语料库）再进行学习，太累了。
        
    - 所以我们一般是让它一次读一小批句子（a batch of sentences），学习一下，调整一下大脑；再读下一批，再学习，再调整……

---

第四部分：反向传播 (BPTT)

既然权重 `W` 在每一步都被**重复使用**了，那我们到底该如何更新它呢？

- **核心思想：责任均摊，累积相加。**
    
    - 讲义里的公式和推导，背后是一个非常直观的道理。
        
    - 想象一下，最终的总损失，就像一个“最终的锅”。我们要把这个“锅”一层层地甩回去，看看谁该为它负责。
        
    - 权重 `W` 在第 `t` 步参与了计算，所以它要为第 `t` 步的损失负一部分责任。
        
    - 但它在第 `t-1` 步也参与了，所以它也要为第 `t-1` 步的损失负一部分责任……
        
    - 最终，权重 `W` **总共要负的责任**，就是它在**每一个时间步**所负的责任的**总和**。
        
- **BPTT (Backpropagation Through Time):**
    
    - 这个算法，就是将我们熟悉的“反向传播”算法，沿着“时间”的轴线，从后往前一步步地传播回去。
        
    - 它把每一个时间步的梯度都计算出来，然后**累加**到总的梯度上，最后用这个总梯度来更新权重 `W`。
        
    - **截断BPTT (Truncated BPTT):** 在实际操作中，把梯度从一句话的结尾一直传到开头，计算量太大，而且“记忆会褪色”。所以我们常常会“偷个懒”，只把梯度往前传个二三十步就不再传了。


---

第五部分：让RNN开口说话。—— 文本生成

一旦我们的RNN学成毕业，我们就可以让它来“即兴创作”啦。

- **生成过程 (Generating roll outs):**
    
    1. 我们给它一个起始词，比如 `<s>` (句子开始符)。
        
    2. RNN思考后，输出一个概率分布，我们从这个分布里**随机抽取 (sample)** 一个词，比如 "my"。
        
    3. 现在，我们把刚刚抽出来的 "my" 作为**下一步的输入**，再喂给RNN。
        
    4. RNN再思考，再输出一个概率分布，我们再抽取一个词，比如 "favorite"。
        
    5. ……循环往复，一个由RNN自己创造的句子就诞生了 。

---

### 3. Problems with RNNs: Vanishing and Exploding Gradients

第一部分：记忆褪色 (Vanishing Gradients)

#### **1. 直觉理解：一场“传话游戏”**

想象一下，我们在玩一个“悄悄话”游戏。

- **“错误信号”：** 在故事的结尾，我们发现模型预测错了，于是我们从结尾大喊一声：“喂。正确答案是‘tickets’啊。这个信息很重要。” 这个喊声，就是我们的“梯度”或“错误信号”。
    
- **时间回溯：** 这个“喊声”需要从句子的结尾，一个人一个人地**反向传播**回句子的开头，去告诉当初看到“tickets”那个词的那个时间步：“嘿，你当初看到的这个词，对结尾很重要，你要记住它。”
    
- **信号衰减：** 可惜的是，RNN的“传话”机制是有损耗的。每往前传一个人，这个声音就会变小一点点。比如，`∂h_t / ∂h_{t-1}` 就像是第 `t` 个人对第 `t-1` 个人传话时的“音量衰减率”。如果这个衰减率是0.8，那么经过20个人传递后，原始的“喊声”就变成了 `0.8^20 ≈ 0.01`，几乎微不可闻了。
    
- **结果：** 当这个微弱如蚊子叫的信号传到句子开头时，那个时间步的权重根本“听不见”这个修正指令，它也就无法学会这个“长距离依赖”。
    

**讲义中的链式法则（chain rule）图解，就是在描绘这个“声音”一步步衰减的过程。**

#### **2. 数学上的证明**

讲义里数学推导的核心思想和“传话游戏”一模一样：

- 我们想计算最终的损失对遥远的 `h_k` 状态的梯度（即“最终的错误”对“遥远的记忆”有多大影响）。
    
- 根据链式法则，这需要将中间每一步的“传话衰减率”`∂h_{i+1}/∂h_i` 全部**连乘**起来。
    
- 在简化情况下，这个“衰减率”可以看作是权重矩阵 `W_h`。如果这个矩阵的“能量”（用特征值衡量）小于1，那么将它连乘很多次 `(W_h)^(t-k)`，结果就会**指数级地趋近于0**。
    
- **结论：梯度消失了 (Gradient Vanishes)。** 从远方传来的“修正指令”在半路就消失了。
    

#### **3. 为什么这是个大问题？**

讲义里那个打印机的例子非常经典。

> "When she tried to print her tickets, she found that the printer was out of toner... she finally printed her ________"

为了能正确预测出最后一个词是 `tickets`，模型必须“记住”在很久之前出现过的 `tickets` 这个词。但由于梯度消失，模型从这个例子中学习到的“修正指令”根本无法传播回那么远的地方。因此，**模型永远学不会这种长距离的依赖关系**，只能根据最后几个词（比如 "printed her"）来瞎猜。

---

第二部分：记忆过载 (Exploding Gradients) 

这个问题和梯度消失恰好相反，它虽然没那么常见，但一旦发生就非常致命。

#### **1. 发生了什么？**

- 还是那个“传话游戏”，但这次，传话的人不但不让声音变小，反而一个比一个喊得更响！
    
- 如果每一步的“传话放大率”`∂h_{i+1}/∂h_i`（即权重矩阵 `W_h` 的能量）**大于1**，那么将它们连乘很多次，信号就会被**指数级放大**，变成一个天文数字！
    

#### **2. 为什么这是个大问题？**

- **SGD更新步长爆炸：** 我们更新权重的方法是 `新权重 = 旧权重 - 学习率 * 梯度`。
    
- 如果梯度变得超级大，那这次更新的“步子”就会迈得特别大！
    
- 讲义里那个比喻非常形象：“**You think you’ve found a hill to climb, but suddenly you’re in Iowa.**” (你以为你只是在小心翼翼地爬山，结果一步迈得太大，直接从山顶飞了出去，掉到了一个完全陌生的、损失函数值极高的糟糕地方！)
    
- 在实际训练中，你会看到损失突然变成一个巨大的数字，或者干脆变成 `NaN` (Not a Number)，整个训练过程直接崩溃！

---

第三部分：解决方案

#### **1. 梯度裁剪 (Gradient Clipping)

这是解决**梯度爆炸**的简单而有效的方法。

- **思想：** 我们给梯度的大小设定一个上限（threshold）。
    
- **操作：** 在进行权重更新之前，我们先检查一下梯度的“总音量”（范数/norm）。如果它超过了我们设定的上限，我们就把它**按比例缩小**，强行拉回到上限以内。
    
- **效果：** 这就像是给一个爱飙车的司机装上了速度限制器。我们不改变他前进的**方向**，但限制了他前进的**步长**，防止他“一步迈太大飞出悬崖”。这是一个非常实用的技巧，在训练RNN时几乎是必备的。
    

#### **2. 解决梯度消失：一个更难的挑战**

梯度消失是RNN结构性的缺陷，裁剪是没用的（你不能把一个快要消失的声音再放大）。我们需要从根本上改变大脑的结构。

- **根本原因：** 在普通的RNN里，`h_t` 这个“瞬时记忆”在每一步都会被**完全重写** (`h_t = tanh(W_h * h_{t-1} + ...)`）。旧的记忆和新的输入被粗暴地搅和在一起，没有一条“VIP通道”让重要的信息长期保存下来。
    
- **解决方案的曙光：**
    
    - **能不能建立一个独立的“记忆模块”？** 这个模块专门用来存放长期记忆，而`h_t`只作为临时的“草稿纸”。信息可以有选择地被写入、读取或遗忘。—— 这就是大名鼎鼎的 **LSTM (长短期记忆网络)** 的核心思想！
        
    - **能不能建立一些“绿色通道”或“直达快线”？** 让梯度可以直接跨越很多时间步传播，绕过那些会衰减的连乘环节。—— 这就是 **残差连接 (Residual Connections)** 和 **注意力机制 (Attention)** 等后续改进的核心思想！

---
### 4. Recap

在深入探讨了n-gram模型、固定窗口模型以及循环神经网络之后，此处的总结至关重要。它旨在精确地区分两个核心概念：**语言模型（Language Model）**作为一项任务，与**循环神经网络（Recurrent Neural Network）**作为一种实现方法。理解这一区别是掌握现代自然语言处理的基础。

#### **1. 语言模型 (Language Model): 任务与目标**

> **定义: "一个预测下一个词的系统 (A system that predicts the next word)"**

语言模型的核心功能并非特指某一种具体的模型结构，而是一项根本性的**任务 (Task)**。其目标是**对文本序列的概率进行建模**。简而言之，它评估一个句子或一段文本在语言学上的“合理性”或“自然程度”，并能基于已有文本预测后续最有可能出现的词语。

例如，对于 P("the students opened their books") 和 P("the students opened their bananas")，一个有效的语言模型会赋予前者远高于后者的概率。

#### **2. 循环神经网络 (Recurrent Neural Network): 架构与方法**

> **定义: "一类能处理序列输入、并在每步应用相同权重的神经网络 (A family of neural networks that take sequential input, apply the same weights on each step...)"**

循环神经网络 (RNN) 是一种具体的**神经网络架构 (Architecture)**，是为处理序列数据而设计的强大**工具 (Tool)**。其核心设计特征包括：

1. **处理可变长度序列：** 能够处理任意长度的输入，克服了固定窗口模型的局限性。
    
2. **权重共享机制：** 通过在每个时间步上复用同一套权重参数进行计算，实现了对序列处理的对称性，极大地提高了参数效率。
    
3. **状态传递机制：** 拥有一个“隐藏状态 (hidden state)”，该状态在时间步之间传递，理论上使得网络能够保留和利用历史信息。
    
4. **灵活的输出模式：** 具备在序列的每个时间步上生成输出的能力，使其能够灵活适应不同的任务需求。
    

#### **3. 核心辨析：任务 ≠ 方法 (LM ≠ RNN)**

> **关键论断: "Recurrent Neural Network ≠ Language Model"**

最关键的认知在于，**实现任务的方法 (RNN) 不等于任务本身 (LM)**。

- RNN 是构建语言模型的一种**强大且有效的方法**，但它不是唯一的方法。历史上，我们使用过 n-gram 统计模型来构建语言模型；未来，我们还将学习更先进的架构，如 Transformer。
    
- 反之，RNN 这一架构也**不局限于**构建语言模型。它同样被广泛应用于其他基于序列的任务，例如时间序列预测、情感分类、命名实体识别等。将 RNN 等同于语言模型是一种概念上的混淆。
    

#### **4. 评估与展望**

- **RNN 作为语言模型的优势与挑战：**
    
    - **优势：** RNN 作为构建语言模型的工具，相较于传统的 n-gram 方法，在解决数据稀疏性问题和降低模型存储需求方面取得了显著的进步，因为它学习的是连续空间中的分布式表示。
        
    - **挑战：** 它也存在固有的问题，即在处理长序列时面临的**梯度消失与梯度爆炸**问题，这限制了其有效捕捉长期依赖的能力。
        
- **RNN 的持续相关性：**
    
    - 尽管存在上述挑战，且后续出现了更为先进的模型架构，但 RNN 的核心思想——**通过循环传递的隐藏状态来建模序列依赖关系**——具有深远的影响。它为后续的序列模型（如提及的状态空间模型 (state space models) 等）的发展奠定了重要的理论基础，至今在学术研究与工业界中仍占有一席之地。